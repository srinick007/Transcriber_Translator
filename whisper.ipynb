{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e811cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sridh\\AppData\\Local\\Temp\\ipykernel_28624\\897549616.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a8cc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b07bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0-dev20220812\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5be1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34af8987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dc5af",
   "metadata": {},
   "source": [
    "# whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bcd2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b076e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34bf490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4597cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"small\" , device=\"cuda\")\n",
    "result = model.transcribe(\"french.mp3\" , task=\"transcribe\")\n",
    "text=result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5beb853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bonjour dans notre collège il y a au moins 600 élèves et 50 professeurs pour 40 salles et 10 salles spécifiques. Mon emploi du temps du lundi et je commence par français à 8h30 jusqu'à 9h20 puis anglais de 9h26 à 10h00 et ensuite de 10h35 à 11h30 français puis on mange 2h00. Après manger il y a sport soit gymnastique ou natation de 2h00 et on finit par maths qui commence à 15h50 et finit à 16h26. L'horaire d'une journée de jupes est de 8h30 à 16h26 Les matières et mes préférences sont ma matière préférée et le français parce que c'est intéressant. Celle que j'aime le moins c'est Histoire Géo je n'arrive pas à suivre et voilà. Les tenues des élèves sont ce qu'on veut. Il faut juste un peu respecter les règles que les tenues ne soient pas vulgaires. Le contenu de mon sac à dos d'une journée normale sur le lundi. Alors j'ai 4 cahiers, 1 cahier de français, 2 cahiers de maths et 1 cahier d'histoire. Je me trouve ma tablette, ma règle et voilà. Et mon carnet et mon agenda. Voilà. Au revoir.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5357bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Life is a focus, life is a purpose. A purpose achieved by virtues which are developed with personal effort, do not gamble on life. It may not happen twice.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(r\"C:\\Users\\sridh\\Desktop\\audio\\10sec.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa95525a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "071eff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang={'ja':'jpn_Jpan',\n",
    "     'en':'eng_Latn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e06a0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpn_Jpan\n"
     ]
    }
   ],
   "source": [
    "if max(probs, key=probs.get) in lang:\n",
    "    print(lang[max(probs, key=probs.get)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec1161",
   "metadata": {},
   "source": [
    "# nllb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1407744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "fasttext.FastText.eprint = lambda x: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db96b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_lang_model = \"lid218e.bin\" # Path of model file\n",
    "\n",
    "detect_model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "#text=\"hello there\"\n",
    "\n",
    "#predictions = detect_model.predict(text, k=1)\n",
    "\n",
    "#print(predictions) #(('__label__arb_Arab'), array([0.99960977]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348942b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_lang = predictions[0][0].replace('__label__', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2303de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e965f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'facebook/nllb-200-distilled-600M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f3cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8d6ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f2d03519e94dc2a8b9d2e799d95692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\anaconda3\\envs\\tf2.4_python3.9\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sridh\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ee21349a88433eaa167363eb560d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dfd9dc3004498faf5cfd90de2a54a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f042ccecdc0244248055666e655ea1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ncepiece.bpe.model\";:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62abe8cdfe2544af9971f16987e4fa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tokenizer.json\";:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaab48ce740e44938532644e95c78909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline('translation', model=translate_model, tokenizer=tokenizer, src_lang=input_lang, tgt_lang=\"jpn_Jpan\", max_length = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a460816",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは,私たちの大学には少なくとも600人の生徒と50人の教師が40部屋と10つの特定の部屋にいます.私の日程は月曜日です. 私は8時30分から9時20分までフランス語から始めます. 9時26分から10時30分まで英語です. それから10時35分から11時30分までフランス語です. それから2時食べます. 食べた後にスポーツがあります. 運動や2時泳ぎです. そして月曜日には数学で終わります. 15時50分から16時26分までです. 靴下の日程は8時30分から16時26分です. テーマと私の好みの内容は私の好みの内容です. そしてフランス語は,それが面白いからです. 私が一番好きなのは,歴史です. 私は到着し,それを守っています. さて,生徒たちは15時50分から16時00分まで,数学上の規則を尊重します. そして,私のスケジュール1日目です. 私は私のスケジュール1に,私のスケジュール1日目,そして私のスケジュール1に,私のスケジュール1の規則を遵守する必要があります.\n"
     ]
    }
   ],
   "source": [
    "output = translator(text)\n",
    "translated_text = output[0]['translation_text']\n",
    "print(translated_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26db18",
   "metadata": {},
   "source": [
    "# building gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d71aa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8918e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\" , device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4780b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text,out_lang):\n",
    "    predictions = detect_model.predict(text, k=1)\n",
    "    \n",
    "    input_lang = predictions[0][0].replace('__label__', '')\n",
    "    \n",
    "    translator = pipeline('translation', model=translate_model, tokenizer=tokenizer, src_lang=input_lang, tgt_lang=out_lang, max_length = 400)\n",
    "    \n",
    "    output = translator(text)\n",
    "    \n",
    "    translated_text = output[0]['translation_text']\n",
    "    \n",
    "    return translated_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transcribe(audio,out_lang):\n",
    "    #whisper\n",
    "    audio = whisper.load_audio(audio)\n",
    "    result = model.transcribe(audio , task=\"transcribe\")\n",
    "    translated=translate(result[\"text\"],out_lang)\n",
    "    return result[\"text\"],translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7194d392",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\inputs.py:319: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\sridh\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sridh\\AppData\\Roaming\\Python\\Python39\\site-packages\\gradio\\processing_utils.py:241: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    title = 'translator (not so fast one😂)', \n",
    "    fn=transcribe, \n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "        gr.Dropdown([\"eng_Latn\",\"jpn_Jpan\", \"spa_Latn\", \"fra_Latn\"]),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"text\"),\n",
    "        gr.Textbox(label=\"translated\"),\n",
    "\n",
    "    ]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd9b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
